# -*- coding: utf-8 -*-
"""DataAnalyticsProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h-dGOMFvgtYYDn1h5FwjlLfv0d_EAIm1
"""

#initializing
import pandas as pd
import openpyxl


df=pd.read_excel("C:\\Users\\abdel\\Downloads\\stanfordMOOCForumPostsSet.xlsx")

print(df.isnull().sum())

#Phase 1: Data Cleaning
df=pd.read_excel("C:\\Users\\abdel\\Downloads\\stanfordMOOCForumPostsSet.xlsx")

# step 1:  emptied missing Text values which are null by dropping them since they make the data useless

df = df.dropna(subset=['Text']) # drop rows where text is null


# Step 2: Fill missing course_type values using the extracted value from course_name
def extract_course_type(course_display_name):
    if pd.isnull(course_display_name):
        return None
    return course_display_name.split('/')[0]
df['CourseType'] = df['CourseType'].fillna(df['course_display_name'].apply(extract_course_type))

#Step 3: Remove missing rows from the forum_post_id
df = df.dropna(subset=['forum_post_id'])

#Step 4: Fill missing course_display_name values using the extracted value from course_type
df['course_display_name'] = df['course_display_name'].fillna(df['CourseType'])

#Step 5: Remove null values from the forum_uid column
df = df.dropna(subset=['forum_uid'])

#step 6: Since the rest of the columns are interlinked they all have been removed in the previous steps.

print(df.isnull().sum())

#Phase 2: Encode categorical variables.
from sklearn.preprocessing import OneHotEncoder

import pandas as pd

# Assuming `df` is your original DataFrame

# Step 1: Only apply one-hot encoding to the categorical columns.
df = pd.get_dummies(df, columns=['CourseType', 'course_display_name', 'post_type'])

# Step 2: Check the resulting DataFrame
print(df)

#Phase 3: encoding date and scaling it b\w 0-1

import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# If needed: convert 'created_at' to datetime
df['created_at'] = pd.to_datetime(df['created_at'], format='%m/%d/%Y  %I:%M:%S %p')

# Add new datetime-based features
df['hour'] = df['created_at'].dt.hour
df['minute'] = df['created_at'].dt.minute
df['second'] = df['created_at'].dt.second
df['day'] = df['created_at'].dt.day
df['month'] = df['created_at'].dt.month
df['year'] = df['created_at'].dt.year
df['dayofweek'] = df['created_at'].dt.dayofweek
df['is_weekend'] = df['dayofweek'].apply(lambda x: 1 if x >= 5 else 0)

# Initialize the MinMaxScaler instance
scaler = MinMaxScaler()

# Scale the datetime-related features to the range [0, 1]
df['hour_scaled'] = scaler.fit_transform(df[['hour']])
df['minute_scaled'] = scaler.fit_transform(df[['minute']])
df['second_scaled'] = scaler.fit_transform(df[['second']])
df['day_scaled'] = scaler.fit_transform(df[['day']])
df['month_scaled'] = scaler.fit_transform(df[['month']])
df['dayofweek_scaled'] = scaler.fit_transform(df[['dayofweek']])

# For 'is_weekend', it is already a binary value (0 or 1), so no scaling is needed.

# Output the DataFrame to check
print(df[['hour', 'minute', 'second', 'day', 'month', 'dayofweek', 'is_weekend',
          'hour_scaled', 'minute_scaled', 'second_scaled', 'day_scaled',
          'month_scaled', 'dayofweek_scaled']].head())

# Print the column names to check if the new features were added
print(df.columns.tolist())

#Phase 4: Using islation forest to track outliers

from sklearn.ensemble import IsolationForest

# Select the numerical features to be used for outlier detection
features_to_use = ['hour_scaled', 'minute_scaled', 'second_scaled', 'day_scaled',
                  'month_scaled', 'dayofweek_scaled', 'Sentiment(1-7)',
                  'Urgency(1-7)', 'Confusion(1-7)', 'up_count', 'reads']

# Fit the Isolation Forest model
iso_forest = IsolationForest(contamination=0.05)  # 5% contamination (outliers)
outliers_iso = iso_forest.fit_predict(df[features_to_use])

# -1 indicates an outlier, 1 indicates an inlier
df['outlier_iso'] = outliers_iso

# Visualize the outliers - Outliers will be labeled as -1
outliers = df[df['outlier_iso'] == -1]

# Output the dataframe with outlier labels but without dropping the rows
print(outliers.head())
print(len(df))

#Phase 5: EDA (summary and visualiztion)
import matplotlib.pyplot as plt
import seaborn as sns


print(df.describe())

sns.set(style="whitegrid")

#histogram
df.hist(bins=20, figsize=(15, 10))
plt.suptitle('Histograms of Numerical Features')
plt.tight_layout()
plt.show()


#boxplots
boxplot_cols = [
    'Sentiment(1-7)',
    'Urgency(1-7)',
    'Confusion(1-7)',
    'reads',
    'up_count'
]

# Generate individual boxplots
for col in boxplot_cols:
    plt.figure(figsize=(6, 4))
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col}')
    plt.tight_layout()
    plt.show()




#heatmap
heatmap_features = [
    'Sentiment(1-7)',
    'Urgency(1-7)',
    'Confusion(1-7)',
    'reads',
    'up_count',
    'day_scaled',
    'month_scaled'
]

# Compute the correlation matrix
correlation_matrix = df[heatmap_features].corr()

# Plot the heatmap
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Select only numerical features (you can customize this list)
numerical_df = df.select_dtypes(include=['float64', 'int64'])

# 2. Optional: Drop low-variance or uninformative columns
from sklearn.feature_selection import VarianceThreshold
selector = VarianceThreshold(threshold=0.01)
high_variance_df = numerical_df.loc[:, selector.fit(numerical_df).get_support()]

# 3. Compute the correlation matrix
corr_matrix = high_variance_df.corr()

# 4. Optional: Filter to show only strong correlations (e.g., > 0.3 or < -0.3)
strong_corr = corr_matrix[(corr_matrix > 0.3) | (corr_matrix < -0.3)]
mask = strong_corr.isnull()

# 5. Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(strong_corr, annot=True, fmt=".2f", cmap="coolwarm", mask=mask)
plt.title("Filtered Correlation Heatmap")
plt.tight_layout()
plt.show()


# 1. Select only numerical features (you can customize this list)
numerical_df = df.select_dtypes(include=['float64', 'int64'])

# 2. Optional: Drop low-variance or uninformative columns
from sklearn.feature_selection import VarianceThreshold
selector = VarianceThreshold(threshold=0.01)
high_variance_df = numerical_df.loc[:, selector.fit(numerical_df).get_support()]

# 3. Compute the correlation matrix
corr_matrix = high_variance_df.corr()

# 4. Optional: Filter to show only strong correlations (e.g., > 0.3 or < -0.3)
strong_corr = corr_matrix[(corr_matrix > 0.3) | (corr_matrix < -0.3)]
mask = strong_corr.isnull()

# 5. Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(strong_corr, annot=True, fmt=".2f", cmap="coolwarm", mask=mask)
plt.title("Filtered Correlation Heatmap")
plt.tight_layout()
plt.show()


#pairplots
df_combined = pd.concat([df], axis=1)

features_for_pairplot = ['Sentiment(1-7)', 'Urgency(1-7)', 'Confusion(1-7)',
                         'day_scaled', 'month_scaled','reads']


# If post_type and CourseType are one-hot encoded, they should already be numerical in the dataframe
# Plot the pairplot
sns.pairplot(df[features_for_pairplot])





# Show the plot
plt.show()


print(df.columns)

#Step 6:Co-relation analysis to monitor relationships between key features such as the ugrnecy and the text count, and the reads (if a text is biggerr or has more reads, then it is more likely to be urgent)

#Step 7:Feature engineering, applying new relevant features through pre-existing features

# Feature: Question mark presence
df['has_question_mark'] = df['Text'].apply(lambda x: 1 if '?' in str(x) else 0)

# Feature: Word count done previouosly in cell above


# Feature: Urgent keywords
urgent_keywords = ['urgent', 'immediately', 'help', 'asap', 'canâ€™t access', 'emergency']
df['has_urgent_keywords'] = df['Text'].apply(
    lambda x: 1 if any(word in str(x).lower() for word in urgent_keywords) else 0
)
from scipy.stats import pointbiserialr

df['Urgency(1-7)'] = df['Urgency(1-7)'].apply(lambda x: 1 if x >= 4 else 0)
print(df['Urgency(1-7)'].unique())

# Add a column for word count
df['word_count'] = df['Text'].apply(lambda x: len(str(x).split()))

# Correlation between Urgency and Word Count
corr_wc, pval_wc = pointbiserialr(df['word_count'], df['Urgency(1-7)'])

# Correlation between Urgency and Reads
corr_reads, pval_reads = pointbiserialr(df['reads'], df['Urgency(1-7)'])

corr_up, pval_up = pointbiserialr(df['up_count'], df['Urgency(1-7)'])

# Print results
print(f"Correlation between Urgency and Word Count: {corr_wc:.4f} (p-value = {pval_wc:.4f})")
print(f"Correlation between Urgency and Reads: {corr_reads:.4f} (p-value = {pval_reads:.4f})")
print(f"Correlation between Upcount and Urgency: {corr_up:.4f} (p-value = {pval_up:.4f})")

# Select numeric and boolean columns, excluding the target
numeric_cols = df.select_dtypes(include=['number', 'bool']).columns.drop('Urgency(1-7)', errors='ignore')

# Dictionary to store correlation results
correlation_results = {}

# Compute point biserial correlation for each numeric feature
for col in numeric_cols:
    corr, pval = pointbiserialr(df[col], df['Urgency(1-7)'])
    correlation_results[col] = (corr, pval)

# Print results
print("Correlation analysis with Urgency (binary):")
for feature, (corr, pval) in correlation_results.items():
    print(f"- {feature}: Correlation = {corr:.4f}, p-value = {pval:.4f}")



#print(df.info())  # Summary: dtypes, non-nulls, memory usage

#print(df.shape)  # (rows, columns)

#print(df.head())  # First 5 rows

from sklearn.metrics import accuracy_score, f1_score, classification_report

df_model=df[['Opinion(1/0)','Question(1/0)','Confusion(1-7)','outlier_iso',
'has_question_mark',

]]
dfmodel=df_model[df_model['outlier_iso'] == 0]  # Keep only inliers

from sklearn.model_selection import train_test_split


y = df['Urgency(1-7)']

X_train, X_test, y_train, y_test = train_test_split(df_model, y, test_size=0.2, random_state=42)

#logistic regression
from sklearn.linear_model import LogisticRegression

log_reg = LogisticRegression(max_iter=30000)
log_reg.fit(X_train, y_train)
y_pred_lg = log_reg.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred_lg))
print("Weighted F1 Score:", f1_score(y_test, y_pred_lg, average='weighted'))
print("Urgent Class F1 Score:", f1_score(y_test, y_pred_lg, pos_label=1))  # Assuming '1' = urgent

print("\nDetailed Classification Report:")
print(classification_report(y_test, y_pred_lg))

from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.tree import DecisionTreeClassifier

dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train,y_train)
y_pred_dt=dt_model.predict(X_test)

accuracy_dt=accuracy_score(y_test,y_pred_dt)
weighted_f1_dt=f1_score(y_test,y_pred_dt,average='weighted')
report_dt=classification_report(y_test,y_pred_dt,output_dict=True)
urgent_f1_dt=report_dt['1']['f1-score']

print(f"Training data size: {len(X_train)} records")
print(f"Test data size: {len(X_test)} records")

print(f"Accuracy: {accuracy_dt:.4f}")
print(f"Weighted F1 Score: {weighted_f1_dt:.4f}")
print(f"Urgent Class F1 Score: {urgent_f1_dt:.4f}\n")

print("Detailed Classification Report:")
print(classification_report(y_test, y_pred_dt))

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report

# Step 1: Initialize the model
rf_model = RandomForestClassifier(random_state=42)

# Step 2: Train the model
rf_model.fit(X_train, y_train)

# Step 3: Make predictions
y_pred_rf = rf_model.predict(X_test)

print(f"Training data size: {len(X_train)} records")
print(f"Test data size: {len(X_test)} records")

# Step 4: Evaluate performance
accuracy = accuracy_score(y_test, y_pred_rf)
weighted_f1 = f1_score(y_test, y_pred_rf, average='weighted')
urgent_f1 = f1_score(y_test, y_pred_rf, pos_label=1)

# Print results
print("Accuracy:", round(accuracy, 4))
print("Weighted F1 Score:", round(weighted_f1, 4))
print("Urgent Class F1 Score:", round(urgent_f1, 4))
print("\nDetailed Classification Report:")
print(classification_report(y_test, y_pred_rf))

#support vector machine

from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score

# Initialize the SVM model with a radial basis function (RBF) kernel
svm_model = SVC(kernel='rbf', random_state=42,class_weight='balanced')

# Train the SVM model on the training data
svm_model.fit(X_train, y_train)

# Predict using the trained SVM model on the test data
y_pred_svm = svm_model.predict(X_test)

# Evaluate the SVM model
accuracy_svm = accuracy_score(y_test, y_pred_svm)
print(f'Accuracy: {accuracy_svm}')

# Get the classification report for each class
print("Accuracy:", round(accuracy_svm, 4))
print("Weighted F1 Score:", round(weighted_f1, 4))
print("Urgent Class F1 Score:", round(urgent_f1, 4))
print('Classification Report:')
print(classification_report(y_test, y_pred_svm))